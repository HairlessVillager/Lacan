{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05582bcf-081c-42fe-a3f6-91b82fb7c723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install gensim==4.1.2\n",
    "\n",
    "# 这是一个词向量训练库\n",
    "# 本来打算分词的，但后来因为数据集过小，\n",
    "# 所以我取消了这个的想法\n",
    "# （也就是说 gensim 没有实质性作用）\n",
    "# 但这个程序依赖这个库，我也懒得改了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9123f26-57dc-4a9a-8fc4-161d78e886ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这是训练的部分，需要GPU\n",
    "# 如果只是使用，就不用看这里了\n",
    "# 你首先要准备类似 拉康黑话数据集.txt 一样的文本\n",
    "# 才能准备 words.model 那样的 gensim 词向量文件\n",
    "# words.model 的创建看下一格\n",
    "# 由于训练时数据会全部加载入内存中，所以请保证CPU内存充足\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataLoad import TextData\n",
    "from torch import optim\n",
    "from net import myModle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "LR = 0.003\n",
    "BS = 32\n",
    "\n",
    "data = TextData(\"拉康黑话数据集.txt\",\"words.model\", 10)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "network = myModle(words_num=data.dict_len, hidden_size=50).to(device)\n",
    "\n",
    "loader = DataLoader(dataset=data,batch_size=BS,shuffle=True)\n",
    "optimizer = optim.Adam(params=network.parameters(),lr=LR)\n",
    "loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "drawY = np.array([])\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    for i, data in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        data = data.to(torch.long)\n",
    "        index = data[:,1:] # (句数, 句中第几个词？) 每个单元装一个索引\n",
    "        inp = network(data)[:, :-1, :] # 输出是一个概率分布 (句数, 句中第几个词？ 词表)\n",
    "        inp = torch.transpose(inp, 2, 1)  # (句数, 词表, 句中第几个词？)\n",
    "        l = loss(inp, index)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    drawY = np.append(drawY, l.item())\n",
    "plt.plot(np.arange(len(drawY)),drawY)\n",
    "plt.show()\n",
    "\n",
    "torch.save(network, '拉康快乐机.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375b683c-9aee-4da1-9405-c2e040bd457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words.model 的创建，如果只是使用，就不用看这里了\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import PathLineSentences\n",
    "\n",
    "input_dir = input(\"请输入语料文件：\")\n",
    "f = open(input_dir, \"r\",encoding=\"utf-8\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "model = Word2Vec(text, vector_size=50, window=10, min_count=2,\n",
    "                 workers=multiprocessing.cpu_count(), epochs=100)\n",
    "\n",
    "model.save(\"words.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1567f-a07a-442b-90cc-a49ab2eb627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行本单元格，开始成为精神分析大师！\n",
    "# 确实有新的句子，但严重过拟合……\n",
    "# 没什么好说的，它需要更多数据！\n",
    "import using\n",
    "using.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
